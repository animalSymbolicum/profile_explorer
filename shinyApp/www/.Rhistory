predictions <- predict(modelFit, newdata = testing)
confusionMatrix(predictions, testing$diagnosis)
IL_str <- grep("^IL", colnames(training), value = TRUE)
## make a subset of these predictors
predictors_IL <- predictors[, IL_str]
df <- data.frame(diagnosis, predictors_IL)
inTrain = createDataPartition(df$diagnosis, p = 3/4)[[1]]
training = df[inTrain, ]
testing = df[-inTrain, ]
## train the data using the first method
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
##
## Attaching package: 'e1071'
##
## The following object is masked from 'package:Hmisc':
##
##     impute
predictions <- predict(modelFit, newdata = testing)
## get the confustion matrix for the first method
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis, predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[inTrain, ]
testing = adData[-inTrain, ]
Create a training data set consisting of only the predictors with variable names beginning with IL and the diagnosis. Build two predictive models, one using the predictors as they are and one using PCA with principal components explaining 80% of the variance in the predictors. Use method=“glm” in the train function. What is the accuracy of each method in the test set? Which is more accurate?
set.seed(3433)
## grep the predictors starting with 'IL'
IL_str <- grep("^IL", colnames(training), value = TRUE)
## make a subset of these predictors
predictors_IL <- predictors[, IL_str]
df <- data.frame(diagnosis, predictors_IL)
inTrain = createDataPartition(df$diagnosis, p = 3/4)[[1]]
training = df[inTrain, ]
testing = df[-inTrain, ]
## train the data using the first method
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
##
## Attaching package: 'e1071'
##
## The following object is masked from 'package:Hmisc':
##
##     impute
predictions <- predict(modelFit, newdata = testing)
## get the confustion matrix for the first method
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
grep("^IL", colnames(training), value = TRUE)
subNames
adData
names(ad)
names(adData)
adData = data.frame(diagnosis,predictors_IL)
names(adData)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
## without PCA
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
predictions <- predict(modelFit, newdata = testing)
confusionMatrix(predictions, testing$diagnosis)
names(training) %>% str_subset("^IL.+") -> subNames
predictors_IL <- predictors[, subNames]
adData = data.frame(diagnosis,predictors_IL)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
## without PCA
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
predictions <- predict(modelFit, newdata = testing)
confusionMatrix(predictions, testing$diagnosis)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
names(training) %>% str_subset("^IL.+") -> subNames
predictors_IL <- predictors[, subNames]
adData = data.frame(diagnosis,predictors_IL)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
## without PCA
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
predictions <- predict(modelFit, newdata = testing)
confusionMatrix(predictions, testing$diagnosis)
preProc <- preProcess(training[, subNames], method = "pca", thresh = 0.8)
predictions <- predict(preProc, training[, subNames])
modelFit <- train(diagnosis ~ ., method = "glm", data = preProc)
modelFit <- train(diagnosis ~ ., method = "glm", data = predictions)
predictions
names(predictions)
preProc <- preProcess(training, method = "pca", thresh = 0.8)
predictions <- predict(preProc, training)
modelFit <- train(diagnosis ~ ., method = "glm", data = predictions)
confusionMatrix(trainedPreditctions, testing$diagnosis)
confusionMatrix(modelFit, testing$diagnosis)
confusionMatrix(testing$diagnosis, predict(modelFit, testing))
names(testing)
confusionMatrix(testing$diagnosis, predict(modelFit, testing))
predict(modelFit, testing)
testing
modelFit
modelFit <- train(diagnosis ~ ., method = "glm", data = predictions)
confusionMatrix(testing$diagnosis, predict(modelFit, testing))
confusionMatrix(testing$diagnosis, predict(modelFit, predict(predictions, testing)))
predict(predictions, testing)
predictions
predicts <- predict(preProc, training)
modelFit <- train(diagnosis ~ ., method = "glm", data = predicts)
confusionMatrix(testing$diagnosis, predict(modelFit, testing))
modelFit
predict(modelFit, testing)
testing
names(testing)
modelFit <- train(diagnosis ~ ., method = "glm", data = predicts)
preProc <- preProcess(training, method = "pca", thresh = 0.8)
predicts <- predict(preProc, training)
modelFit <- train(diagnosis ~ ., method = "glm", data = predicts)
confusionMatrix(testing$diagnosis, predict(modelFit, testing))
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
names(training) %>% str_subset("^IL.+") -> subNames
IL_VARS <- predictors[, subNames]
adData = data.frame(diagnosis,IL_VARS)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
## without PCA
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
predictions <- predict(modelFit, newdata = testing)
confusionMatrix(predictions, testing$diagnosis)
## with PCA
preProc <- preProcess(training, method = "pca", thresh = 0.8)
predicts <- predict(preProc, training)
modelFit <- train(diagnosis ~ ., method = "glm", data = predicts)
confusionMatrix(testing$diagnosis, predict(modelFit, testing))
summary(modelFit)
library(caret)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
segmentationOriginal
names(segmentationOriginal)
segmentationOriginal$Case
library(sqldf)
sqldf()
sqldf("fotolia_full")
getOption("sqldf.verbose")
getOption("sqldf.connection"),
verbose = isTRUE(getOption("sqldf.verbose"))
getOption("sqldf.connection")
RSQLite::SQLite()
source('/Volumes/Boxcryptor/Dropbox/Mechanical_Animals/10_JellyFish/10_Library/jellyHelpers.R')
dbCloseAll()
library(magrittr)
library(purrr)
dbCloseAll()
library(DBI)
dbCloseAll()
dbCloseAll(sqldf)
dbCloseAll()
source('/Volumes/Boxcryptor/Dropbox/Mechanical_Animals/10_JellyFish/10_Library/jellySetup.R')
dbCloseAll()
source('/Volumes/Boxcryptor/Dropbox/Mechanical_Animals/10_JellyFish/10_Library/jellyHelpers.R')
dbCloseAll()
dbCloseAll()
dbCloseAll()
drv = PostgreSQL())
PostgreSQL()
dbListConnections(NULL)
drv = PostgreSQL()
dbListConnections(drv) %>%
# close each
map(~ dbDisconnect(.x) )
dbCloseAll()
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(3433)
mod_rf <- train(diagnosis ~ ., data = training, method = "rf")
mod_gbm <- train(diagnosis ~ ., data = training, method = "gbm")
mod_lda <- train(diagnosis ~ ., data = training, method = "lda")
pred_rf <- predict(mod_rf, testing)
pred_gbm <- predict(mod_gbm, testing)
pred_lda <- predict(mod_lda, testing)
predDF <- data.frame(pred_rf, pred_gbm, pred_lda, diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~ ., method = "rf", data = predDF)
combPred <- predict(combModFit, predDF)
install.packages("gbm")
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(3433)
mod_rf <- train(diagnosis ~ ., data = training, method = "rf")
mod_gbm <- train(diagnosis ~ ., data = training, method = "gbm")
mod_lda <- train(diagnosis ~ ., data = training, method = "lda")
pred_rf <- predict(mod_rf, testing)
pred_gbm <- predict(mod_gbm, testing)
pred_lda <- predict(mod_lda, testing)
predDF <- data.frame(pred_rf, pred_gbm, pred_lda, diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~ ., method = "rf", data = predDF)
combPred <- predict(combModFit, predDF)
library(gbm)
library(caret)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(3433)
mod_rf <- train(diagnosis ~ ., data = training, method = "rf")
library(gbm)
library(caret)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(3433)
mod_rf <- train(diagnosis ~ ., data = training, method = "rf")
mod_gbm <- train(diagnosis ~ ., data = training, method = "gbm")
mod_lda <- train(diagnosis ~ ., data = training, method = "lda")
pred_rf <- predict(mod_rf, testing)
pred_gbm <- predict(mod_gbm, testing)
pred_lda <- predict(mod_lda, testing)
predDF <- data.frame(pred_rf, pred_gbm, pred_lda, diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~ ., method = "rf", data = predDF)
combPred <- predict(combModFit, predDF)
# Accuracy using random forests
confusionMatrix(pred_rf, testing$diagnosis)$overall[1]
##  Accuracy
## 0.7804878
# Accuracy using boosting
confusionMatrix(pred_gbm, testing$diagnosis)$overall[1]
## Accuracy
## 0.804878
# Accuracy using linear discriminant analysis
confusionMatrix(pred_lda, testing$diagnosis)$overall[1]
##  Accuracy
## 0.7682927
# Stacked Accuracy
confusionMatrix(combPred, testing$diagnosis)$overall[1]
library(gbm)
library(caret)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
mod_rf <- train(diagnosis ~ ., data = training, method = "rf")
mod_gbm <- train(diagnosis ~ ., data = training, method = "gbm")
mod_lda <- train(diagnosis ~ ., data = training, method = "lda")
pred_rf <- predict(mod_rf, testing)
pred_gbm <- predict(mod_gbm, testing)
pred_lda <- predict(mod_lda, testing)
predDF <- data.frame(pred_rf, pred_gbm, pred_lda, diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~ ., method = "rf", data = predDF)
combPred <- predict(combModFit, predDF)
# Accuracy using random forests
confusionMatrix(pred_rf, testing$diagnosis)$overall[1]
##  Accuracy
## 0.7804878
# Accuracy using boosting
confusionMatrix(pred_gbm, testing$diagnosis)$overall[1]
## Accuracy
## 0.804878
# Accuracy using linear discriminant analysis
confusionMatrix(pred_lda, testing$diagnosis)$overall[1]
##  Accuracy
## 0.7682927
# Stacked Accuracy
confusionMatrix(combPred, testing$diagnosis)$overall[1]
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
dim(adData)
set.seed(62433)
fitRf <- train(diagnosis ~ ., data = training, method = "rf")
fitGBM <- train(diagnosis ~ ., data = training, method = "gbm")
fitLDA <- train(diagnosis ~ ., data = training, method = "lda")
predRf <- predict(fitRf, testing)
predGBM <- predict(fitGBM, testing)
predLDA <- predict(fitLDA, testing)
pred <- data.frame(predRf, predGBM, predLDA, diagnosis=testing$diagnosis)
# Stack the predictions together using random forests ("rf")
fit <- train(diagnosis ~., data = pred, method = "rf")
predFit <- predict(fit, testing)
c1 <- confusionMatrix(predRf,  testing$diagnosis)$overall[1]
c2 <- confusionMatrix(predGBM,  testing$diagnosis)$overall[1]
c3 <- confusionMatrix(predLDA, testing$diagnosis)$overall[1]
c4 <- confusionMatrix(predFit, testing$diagnosis)$overall[1]
print(paste(c1, c2, c3, c4))
packeges()
package_version("caret")
package_version(caret)
package_version("caret")
library(caet)
library(caret)
package_version("caret")
packageVersion("caret")
set.seed(7365483)
set.seed(73653)
rnworm(1,2,3)
rnorm(1,2,3)
rnorm(1,2,3)
rnorm(1,2,3)
set.seed(73653)
rnorm(1,2,3)
urlTraining   <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
urlValidation <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
# load data & code 'NA', '' and '#DIV/0!' as missing values
trainingData   <- read.csv(url(urlTraining), header=TRUE, sep=",", na.strings=c("NA","#DIV/0!",""))
validationData <- read.csv(url(urlValidation), header=TRUE, sep=",", na.strings=c("NA","#DIV/0!",""))
trainingData[1:10, 1:7]
names(data)
names(trainingData)
trainingData$kurtosis_roll_belt
trainingData[-1:7, ]
trainingData[, -c(1:7)]
trainingData <- trainingData[, -c(1:7)]
validationData <- validationData[, -c(1:7)]
trainingData %>% apply(2, function(column) any(is.na(column)))
library(maggritr)
# load packages
library(caret)
library(dplyr)
library(ggplot2)
library(maggritr)
trainingData %>% apply(2, function(column) any(is.na(column)))
NAFilter <- apply(trainingData, 2, function(column) !any(is.na(column)))
NAFilter
notMissingFilter <- apply(trainingData, 2, function(column) !any(is.na(column)))
# subset variables without any NAs
trainingData <- trainingData[, notMissingFilter]
validationData <- validationData[, notMissingFilter]
sapply(trainingData, 2, type)
apply(trainingData, 2, type)
apply(trainingData, 2, class)
numericIndex <- 1:(ncol(trainingData)-1)
numericIndex
validationData[, numericIndex]
trainingData[, numericIndex]
trainingData[, numericIndex] <- as.numeric(trainingData[, numericIndex])
validationData[, numericIndex] <- as.numeric(validationData[, numericIndex])
as.numeric(trainingData[, numericIndex])
trainingData[, numericIndex] <- apply(trainingData[, numericIndex], 2, as.numeric)
trainingData %>% str
validationData[, numericIndex] <- apply(validationData[, numericIndex], 2, as.numeric)
findCorrelation(cor(trainingData[, numericIndex]), cutoff=0.9)
highlyCorrelatedIndex <- findCorrelation(cor(trainingData[, numericIndex]), cutoff=0.9)
trainingData[, -highlyCorrelatedIndex]
trainingData   <- trainingData[, -highlyCorrelatedIndex]
validationData <- validationData[, -highlyCorrelatedIndex]
nearZeroVar(trainData)
trainData <- read.csv(url(urlTraining), header=TRUE, sep=",", na.strings=c("NA","#DIV/0!",""))
validData <- read.csv(url(urlValidation), header=TRUE, sep=",", na.strings=c("NA","#DIV/0!",""))
trainData <- trainData[, -c(1:7)]
validData <- validData[, -c(1:7)]
# identify variables not containing any NA values
notMissingFilter <- apply(trainData, 2, function(column) !any(is.na(column)))
# subset variables without any NAs
trainData <- trainData[, notMissingFilter]
validData <- validData[, notMissingFilter]
# transform variable class to numeric except for 'classe' & 'problem_id'
numericIndex <- 1:(ncol(trainData)-1)
trainData[, numericIndex] <- apply(trainData[, numericIndex], 2, as.numeric)
validData[, numericIndex] <- apply(validData[, numericIndex], 2, as.numeric)
# identify highly correlated variables to
highlyCorrelatedIndex <- findCorrelation(cor(trainData[, numericIndex]), cutoff=0.9)
# exclude highly correlated variables from data
trainData <- trainData[, -highlyCorrelatedIndex]
validData <- validData[, -highlyCorrelatedIndex]
nearZeroVar(trainData)
ifelse(TRUE, stop("what"), "a")
length(zeroVarianceIndex) != 0
zeroVarianceIndex <- nearZeroVar(trainData)
length(zeroVarianceIndex) != 0
ifelse(length(zeroVarianceIndex) == 0, print("No zero variance variables"), stop("Found zero variables to subsett"))
ifelse(length(zeroVarianceIndex) == 0, print("No zero variance variables"), stop("Found zero variables to subsett"))
length(zeroVarianceIndex) == 0
ifelse(length(zeroVarianceIndex) == 0, print("No zero variance variables"), stop("Found zero variables to subsett"))
ifelse(length(zeroVarianceIndex) == 0, "No zero variance variables", stop("Found zero variables to subsett"))
centralSeed <- 72353
set.seed(centralSeed)
inTrain <- createDataPartition(y=trainData$classe, p=0.6, list=FALSE)
inTrain
preProcess(testing)
names(training)
training <- trainData[inTrain,]
testing  <- trainData[-inTrain,]
names(training)
train(classe ~ ., data = training, method = "rf")
model_rf <- train(classe ~ ., data = training, method = "rf")
model_rf
predictedTrain <- preProcess(trainData[, 1:numericIndex],method=c('knnImpute', 'center', 'scale'))
trainData[, 1:numericIndex]
1:numericIndex
numericIndex
trainData[, numericIndex]
predictedTrain <- preProcess(trainData[, numericIndex],method=c('knnImpute', 'center', 'scale'))
trainData[, numericIndex]
numericIndex
trainData
ncol(trainData)
names(trainData)
predictedTrain <- preProcess(trainData[, -c("classe")],method=c('knnImpute', 'center', 'scale'))
trainData[, -c("classe")]
(trainData[, -"classe"]
)
trainData[, -46]
predictedTrain <- preProcess(trainData[, -46],method=c('knnImpute', 'center', 'scale'))
predictedTrain$classe <- trainData$classe
predictedTrain %>% View()
predictedTrain
predictedTrain$classe <- trainData$classe
predictedTrain
tempPrep <- preProcess(trainData[, -46],method=c('knnImpute', 'center', 'scale'))
predictedTrain <- predict(tempPrep, trainData[, -46])
predictedTrain$classe <- trainData$classe
predictedTrain
validData
validData %>% names
tempPrepValid <- preProcess(validData[, -46],method=c('knnImpute', 'center', 'scale'))
predictedValid <- predict(tempPrepValid, validData[, -46])
predictedValid$problem_id <- validData$problem_id
# set seed and partition trainData in test and training set
set.seed(centralSeed)
inTrain <- createDataPartition(y=trainData$classe, p=0.6, list=FALSE)
training <- trainData[inTrain,]
testing  <- trainData[-inTrain,]
model_rf <- train(classe ~ ., data = training, method = "rf")
library(stringr)
"bla/lsdf/asc.xlsx"
"bla/lsdf/asc.xlsx" %>% str_replace(".+\\/", "")
"bla/lsdf/asc.xlsx" %>% str_replace(".+[/]", "")
library(jsonlite)
Sys.info()
installed.packages()
installed.packages() %>% row.names()
row.names(installed.packages())
dbListConnections(PostgreSQL())
library(DBI)
dbListConnections(PostgreSQL())
library(PostgreSQL)
source('/Volumes/Boxcryptor/Dropbox/Mechanical_Animals/10_JellyFish/10_Library/jellySetup.R')
dbListConnections(PostgreSQL())
lapply
.Internal
.Primitive("lapply")
str_detect(1, "[[:alnum:]]")
library(stringr)
str_detect(1, "[[:alnum:]]")
Sys.info()
paste0(
"                            host     = ",
"ifelse(Sys.info()['sysname'] == 'Darwin', 'localhost', ",
"'", "bla",
# meta %>%
#   filter(class == "db") %>%
#   filter(variable == "host") %>%
#   select(processing),
"')"
)
library(RSelenium)
setwd("/Users/majideismann/Desktop/AidForTradeProfiles(Excel)_e/")
dir()
library(magrittr)
library(dplyr)
library(readxl)
dir()[1] %>%
read_excel(sheet = "Data")
dir()[1] %>%
read_excel(sheet = "Data") %>%
View()
url("http://stat.wto.org/AidForTradeProfiles/AidForTradeProfiles(Excel)_e.zip") %>%
unzip()
url("http://stat.wto.org/AidForTradeProfiles/AidForTradeProfiles(Excel)_e.zip")
√
install.packages('rsconnect')
install.packages('rsconnect')
install.packages("rsconnect")
install.packages("rsconnect")
install.packages("rsconnect")
install.packages("rsconnect")
install.packages("rsconnect")
